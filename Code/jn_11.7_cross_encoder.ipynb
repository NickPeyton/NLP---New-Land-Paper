{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a23702a",
   "metadata": {},
   "source": [
    "# Cross-Encoder Model for Grouping Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c64de",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a744218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import platform\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import phonetics as ph\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "if platform.node() == 'Nick_Laptop':\n",
    "    drive = 'C'\n",
    "elif platform.node() == 'MSI':\n",
    "    drive = 'D'\n",
    "else:\n",
    "    drive = 'uhhhhhh'\n",
    "    print('Uhhhhhhhhhhhhh')\n",
    "os.chdir(f'{drive}:/PhD/DissolutionProgramming/LND---Land-Paper')\n",
    "\n",
    "PROCESSED = 'Data/Processed'\n",
    "RAW = 'Data/Raw'\n",
    "MODELS = f'Code/ml_models/'\n",
    "MODEL_FOLDER = f'{MODELS}/name_matcher'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ad4f0",
   "metadata": {},
   "source": [
    "#### Defining the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebd1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=128, hidden_dim=64, fc_dim=32):\n",
    "        super(CrossEncoder, self).__init__()\n",
    "\n",
    "        # Embedding layer (shared between names and metaphones)\n",
    "        self.name_embedding = nn.Embedding(28, embed_dim)  # Assuming 27 letters + 1 padding\n",
    "        self.metaphone_embedding = nn.Embedding(28, embed_dim)\n",
    "        # BiLSTM for sequence encoding\n",
    "        self.name_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.metaphone_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.fc1 = nn.Linear(4*2 * hidden_dim, fc_dim)  # Combining all four encodings\n",
    "        self.fc2 = nn.Linear(fc_dim, 1)\n",
    "\n",
    "    def name_encode(self, x):\n",
    "        name_embedded = self.name_embedding(x)\n",
    "        _, (name_hidden, _) = self.name_lstm(name_embedded)\n",
    "        name_hidden = torch.cat((name_hidden[0], name_hidden[1]), dim=1)  # Concatenate forward & backward LSTM outputs\n",
    "        return name_hidden\n",
    "    def metaphone_encode(self, x):\n",
    "        metaphone_embedded = self.metaphone_embedding(x)\n",
    "        _, (metaphone_hidden, _) = self.metaphone_lstm(metaphone_embedded)\n",
    "        metaphone_hidden = torch.cat((metaphone_hidden[0], metaphone_hidden[1]), dim=1)  # Concatenate forward & backward LSTM outputs\n",
    "        return metaphone_hidden\n",
    "\n",
    "    def forward(self, name1, metaphone1, name2, metaphone2):\n",
    "        # Encode each input separately\n",
    "        name1_encoded = self.name_encode(name1)\n",
    "        metaphone1_encoded = self.metaphone_encode(metaphone1)\n",
    "        name2_encoded = self.name_encode(name2)\n",
    "        metaphone2_encoded = self.metaphone_encode(metaphone2)\n",
    "        # Concatenate all representations\n",
    "        combined = torch.cat((name1_encoded, metaphone1_encoded, name2_encoded, metaphone2_encoded), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        fc1_out = self.fc1(combined)\n",
    "        fc1_relud = F.relu(fc1_out)\n",
    "        output = torch.sigmoid(self.fc2(fc1_relud))  # Binary classification\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def encode_surname(surname, max_len=24):\n",
    "    CHARSET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0'\n",
    "    CHARSET_DICT = {char: i + 1 for i, char in enumerate(CHARSET)}\n",
    "    PAD = 0\n",
    "    surname = surname.upper()\n",
    "    surname = ''.join([char for char in surname if char in CHARSET])\n",
    "    metaphone = ph.metaphone(surname)\n",
    "\n",
    "    encoded = [CHARSET_DICT[char] for char in surname]\n",
    "    if len(encoded) < max_len:\n",
    "        encoded += [PAD] * (max_len - len(encoded))\n",
    "    encoded = torch.tensor(encoded).long()\n",
    "\n",
    "    encoded_metaphone = [CHARSET_DICT[char] for char in metaphone]\n",
    "    if len(encoded_metaphone) < max_len:\n",
    "        encoded_metaphone += [PAD] * (max_len - len(encoded_metaphone))\n",
    "    encoded_metaphone = torch.tensor(encoded_metaphone).long()\n",
    "\n",
    "    return encoded, encoded_metaphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba613f8",
   "metadata": {},
   "source": [
    "#### Loading or creating the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b13723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded!\n",
      "Encoding surnames...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9d1560347b40258dd6fed16c7ee552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/257944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 8,  5,  1, 22,  5, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0]), tensor([ 8,  6, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0]), tensor([ 8,  5, 22,  5, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0]), tensor([ 8,  6, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0]), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "# Load training data if possible\n",
    "if (os.path.exists(f'{PROCESSED}/surname_training_pairs.csv')):\n",
    "    training_data = pd.read_csv(f'{PROCESSED}/surname_training_pairs.csv')\n",
    "    surname_pairs = [x for x in zip(training_data['name_1'], training_data['name_2'])]\n",
    "    matches = training_data['match'].tolist()\n",
    "    print('Training data loaded!')\n",
    "else:\n",
    "    with open(f'{PROCESSED}/non_combined_surnames.json') as f:\n",
    "        surname_lists = json.load(f)\n",
    "    surname_lists = [x for x in surname_lists if len(x) > 1]\n",
    "\n",
    "    # Combine all the lists into one big pile\n",
    "    surname_pile = []\n",
    "    for surname_list in surname_lists:\n",
    "        surname_pile += surname_list\n",
    "    surname_pile = list(set(surname_pile))\n",
    "    random.shuffle(surname_pile)\n",
    "\n",
    "    # Create EVERY matched pair so the network can learn what a match looks like\n",
    "    surname_lists_copy = surname_lists.copy()\n",
    "    random.shuffle(surname_lists_copy)\n",
    "    surname_pairs = []\n",
    "    for list in surname_lists_copy:\n",
    "        for pair in itertools.combinations(list, 2):\n",
    "            surname_pairs.append(pair)\n",
    "\n",
    "    # Grab 3x as many random pairs as there are matched pairs\n",
    "    combo_list = []\n",
    "    combos = itertools.combinations(surname_pile, 2)\n",
    "    print('Generating random pairs...')\n",
    "    for i,v in tqdm(enumerate(combos), total = (len(surname_pile)*(len(surname_pile)-1))/2):\n",
    "        combo_list.append(v)\n",
    "    selected_combos = random.sample(combo_list, len(surname_pairs)*3)\n",
    "    surname_pairs += selected_combos\n",
    "    matches = []\n",
    "    print('Matching pairs...')\n",
    "    for pair in tqdm(surname_pairs):\n",
    "        if any(pair[0] in x and pair[1] in x for x in surname_lists):\n",
    "            matches.append(1)\n",
    "        else:\n",
    "            matches.append(0)\n",
    "\n",
    "    names_1 = [x[0] for x in surname_pairs]\n",
    "    names_2 = [x[1] for x in surname_pairs]\n",
    "    training_data = pd.DataFrame({'name_1': names_1, 'name_2': names_2, 'match': matches})\n",
    "    training_data.to_csv(f'{PROCESSED}/surname_training_pairs.csv', index=False)\n",
    "\n",
    "# Create the DataLoader for training\n",
    "encoded_surnames_1 = []\n",
    "encoded_metaphones_1 = []\n",
    "encoded_surnames_2 = []\n",
    "encoded_metaphones_2 = []\n",
    "print('Encoding surnames...')\n",
    "for pair in tqdm(surname_pairs):\n",
    "    surname_1 = pair[0]\n",
    "    surname_2 = pair[1]\n",
    "\n",
    "    encoded_1, encoded_metaphone_1 = encode_surname(surname_1)\n",
    "    encoded_2, encoded_metaphone_2 = encode_surname(surname_2)\n",
    "\n",
    "    encoded_surnames_1.append(encoded_1)\n",
    "    encoded_metaphones_1.append(encoded_metaphone_1)\n",
    "    encoded_surnames_2.append(encoded_2)\n",
    "    encoded_metaphones_2.append(encoded_metaphone_2)\n",
    "\n",
    "encoded_surnames_1 = torch.stack(encoded_surnames_1)\n",
    "encoded_metaphones_1 = torch.stack(encoded_metaphones_1)\n",
    "encoded_surnames_2 = torch.stack(encoded_surnames_2)\n",
    "encoded_metaphones_2 = torch.stack(encoded_metaphones_2)\n",
    "matches = torch.tensor(matches).float()\n",
    "\n",
    "dataset = TensorDataset(encoded_surnames_1, encoded_metaphones_1, encoded_surnames_2, encoded_metaphones_2, matches)\n",
    "\n",
    "#%% Train, validate, test split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "print(train_dataset[0])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86aebe8",
   "metadata": {},
   "source": [
    "#### Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a246960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found :(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 1000\n",
    "# Instantiate the model\n",
    "model = CrossEncoder(embed_dim=128, hidden_dim=64, fc_dim=32).to(device)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "os.makedirs(MODEL_FOLDER, exist_ok=True)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_FOLDER, 'cross_encoder_1.pth')))\n",
    "    optimizer.load_state_dict(torch.load(os.path.join(MODEL_FOLDER, 'cross_encoder_1_optim.pth'), map_location=device))\n",
    "    scheduler.load_state_dict(torch.load(os.path.join(MODEL_FOLDER, 'cross_encoder_1_sched.pth')))\n",
    "    print('Model loaded :D')\n",
    "except:\n",
    "    print('No model found :(')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbced4",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8f5aa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m output = model(name1, metaphone_1, name2, metaphone_2)\n\u001b[32m     12\u001b[39m loss = loss_fn(output, match.unsqueeze(\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m loss.backward()\n\u001b[32m     15\u001b[39m optimizer.step()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epoch_array = []\n",
    "val_loss_array = []\n",
    "from IPython.display import display, clear_output\n",
    "plt.ion()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        name1, metaphone_1, name2, metaphone_2, match = [x.to(device) for x in data]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(name1, metaphone_1, name2, metaphone_2)\n",
    "        loss = loss_fn(output, match.unsqueeze(1))\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            name1, metaphone_1, name2, metaphone_2, match = [x.to(device) for x in data]\n",
    "            output = model(name1, metaphone_1, name2, metaphone_2)\n",
    "            loss = loss_fn(output, match.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "    # print(f'Train Loss: {total_loss / len(train_dataloader)}\\nValidation Loss: {val_loss / len(val_dataloader)}')\n",
    "    # print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]}')\n",
    "    scheduler.step(val_loss/len(val_dataloader))\n",
    "\n",
    "    epoch_array.append(epoch)\n",
    "    val_loss_array.append(val_loss/len(val_dataloader))\n",
    "    loss_fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epoch_array, val_loss_array, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss vs Epoch')\n",
    "    plt.show()\n",
    "    plt.pause(0.01)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1.pth'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1_optim.pth'))\n",
    "        torch.save(scheduler.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1_sched.pth'))\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1.pth'))\n",
    "torch.save(optimizer.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1_optim.pth'))\n",
    "torch.save(scheduler.state_dict(), os.path.join(MODEL_FOLDER, 'cross_encoder_1_sched.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14f159",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ffd2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 0.044717861996854055\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        name1, metaphone_1, name2, metaphone_2, match = [x.to(device) for x in data]\n",
    "        output = model(name1, metaphone_1, name2, metaphone_2)\n",
    "        loss = loss_fn(output, match.unsqueeze(1))\n",
    "        eval_loss += loss.item()\n",
    "print(f'Evaluation Loss: {eval_loss / len(test_dataloader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
