{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d02dbd",
   "metadata": {},
   "source": [
    "# Processing the Oxford Dictionary of British Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1e2a7",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355426ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PhD\\DissolutionProgramming\\LND---Land-Paper\\.venv\\Lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\PhD\\DissolutionProgramming\\LND---Land-Paper\\.venv\\Lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "c:\\PhD\\DissolutionProgramming\\LND---Land-Paper\\.venv\\Lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import nltk\n",
    "import shutil\n",
    "import pymupdf\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phonetics as ph\n",
    "from tqdm.notebook import tqdm\n",
    "from pypdf import PdfReader\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "if platform.node() == 'Nick_Laptop':\n",
    "    drive = 'C'\n",
    "elif platform.node() == 'MSI':\n",
    "    drive = 'D'\n",
    "else:\n",
    "    drive = 'uhhhhhh'\n",
    "    print('Uhhhhhhhhhhhhh')\n",
    "os.chdir(f'{drive}:/PhD/DissolutionProgramming/LND---Land-Paper')\n",
    "\n",
    "PROCESSED = 'Data/Processed'\n",
    "RAW = 'Data/Raw'\n",
    "#%%\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "dict_doc = pymupdf.open(f'{RAW}/family_name_dict/family_name_dict.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6faf62",
   "metadata": {},
   "source": [
    "#### Regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1b07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pages to Skip\n",
    "vol_title = re.compile(r'^The Oxford Dictionary')\n",
    "copy_page = re.compile(r'^[0-9]\\n')\n",
    "ed_page = re.compile(r'^Editors and contributors\\n')\n",
    "toc_page = re.compile(r'^Contents\\n')\n",
    "\n",
    "letter_header = re.compile(r'^[A-Z]\\n$')\n",
    "\n",
    "\n",
    "# Fixing missed spaces\n",
    "missed_space = re.compile(r'([A-Za-z]+)([A-Z]+)')\n",
    "missed_space2 = re.compile(r'([0-9]+)([A-Za-z]+)')\n",
    "missed_space3 = re.compile(r'(:)([A-Za-z]+)')\n",
    "\n",
    "# How to grab name blocks\n",
    "start_name_block = re.compile(r'^\\n?([A-Z][\\'-. ]?[A-Za-z\\'-. ]+)\\n\\.\\.\\.')\n",
    "mid_name_block = re.compile(r'\\n?([A-Z][\\'-. ]?[A-Za-z\\'-. ]+)\\n\\.\\.\\.')\n",
    "\n",
    "# Allowed linguistic origins\n",
    "\n",
    "permitted_origins = ['English:',\n",
    "                     'French:',\n",
    "                     'Welsh:',\n",
    "                     'Cornish:',\n",
    "                     'Norman:']\n",
    "\n",
    "# Variants for list\n",
    "variants = re.compile(r'Variants:\\s?((?:[A-Za-z\\']+,?\\s?)+)')\n",
    "see_other = [x + ' see' for x in permitted_origins]\n",
    "variant_of = [re.compile(rf'{x}[a-z\\s,()]+variant\\sof\\s[A-Z][\\'a-z]+[\\'\\-A-Za-z\\s]\\.') for x in permitted_origins]\n",
    "\n",
    "# Early Bearers to add to name list as well\n",
    "early_bearers = re.compile(r'\\nEarly bearers:')\n",
    "references = re.compile(r'\\nReferences:')\n",
    "\n",
    "occupational_surname_pattern = re.compile(\n",
    "    r\"[Oo]ccupational name [A-Za-z(),\\s]+('[A-Za-z\\s]+')\"\n",
    ")\n",
    "occupational_surname = re.compile(r'[Oo]ccupational name')\n",
    "locative_surname_pattern = re.compile(\n",
    "    r'[Ll]ocative name from\\s([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*)'\n",
    "    r'(?: in\\s([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*))?'\n",
    "    r' \\((\\w+)\\)'\n",
    ")\n",
    "devon_pattern = re.compile(r'([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*) \\(Devon\\)')\n",
    "locative_surname = re.compile(r'[Ll]ocative name')\n",
    "topo_surname = re.compile(r'(toponym|topograph)')\n",
    "nickname = re.compile(r'[Nn]ickname from')\n",
    "relationship_name = re.compile(r'[Rr]elationship name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf8e17",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fa6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_unicode_numbers(text: str) -> str:\n",
    "    return ''.join(\n",
    "        chr(ord(c) - 0xF700) if '\\uf730' <= c <= '\\uf739' else c\n",
    "        for c in text\n",
    "    )\n",
    "\n",
    "\n",
    "def fix_ligatures(text):\n",
    "    ligature_map = {\n",
    "        \"ﬁ\": \"fi\",\n",
    "        \"ﬂ\": \"fl\",\n",
    "        \"ﬃ\": \"ffi\",\n",
    "        \"ﬄ\": \"ffl\",\n",
    "        \"ﬅ\": \"ft\",\n",
    "        \"ﬆ\": \"st\"\n",
    "    }\n",
    "    for ligature, replacement in ligature_map.items():\n",
    "        text = text.replace(ligature, replacement)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb8ccb",
   "metadata": {},
   "source": [
    "#### Assembling the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0417284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133b5f3fecc04c739637982f3f93acea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text_list = []\n",
    "for page_num in tqdm(range(122, 3138)):\n",
    "    \n",
    "    test_page = dict_doc[page_num]\n",
    "    text_blocks = test_page.get_text('blocks')\n",
    "    if len(text_blocks) == 0:\n",
    "        continue\n",
    "    text_blocks.sort(key=lambda x: x[-2])\n",
    "    text_blocks = [x[4] for x in text_blocks]\n",
    "    text_blocks = [fix_unicode_numbers(x) for x in text_blocks]\n",
    "    text_blocks = [fix_ligatures(x) for x in text_blocks]\n",
    "    text_blocks = [x.replace('’', \"'\") for x in text_blocks]\n",
    "\n",
    "    if re.search(vol_title, text_blocks[0]) or re.search(copy_page, text_blocks[0]) or re.search(ed_page, text_blocks[0]) or re.search(toc_page, text_blocks[0]):\n",
    "        continue\n",
    "    if re.search(letter_header, text_blocks[0]):\n",
    "        text_blocks = text_blocks[1:-1]\n",
    "    else:\n",
    "        text_blocks = text_blocks[:-2]\n",
    "    text_list.extend(text_blocks)\n",
    "    new_list = []\n",
    "\n",
    "for text in text_list:\n",
    "\n",
    "    if new_list and not re.search(start_name_block, text):\n",
    "        new_list[-1] += '\\n' + text  # Append to the last element\n",
    "    else:\n",
    "        new_list.append(text)\n",
    "\n",
    "text_list = new_list\n",
    "\n",
    "#%%\n",
    "num_shit = 0\n",
    "new_list = []\n",
    "for text in text_list:\n",
    "    if len(re.findall(mid_name_block, text)) > 1:\n",
    "        num_shit += len(re.findall(mid_name_block, text))\n",
    "        text = re.sub(mid_name_block, r'\\n\\n\\n\\1', text)\n",
    "        new_text_blocks = text.split('\\n\\n\\n')\n",
    "        for new_block in new_text_blocks[1:]:\n",
    "            print(new_block)\n",
    "            print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        print('0000000000000000000000000000000000000000000000000000000000000000')\n",
    "        new_list += new_text_blocks[1:]\n",
    "        continue\n",
    "    new_list += [text]\n",
    "print(num_shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81cb9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2f61ba30cb4f7582ea8924c4b1f4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "new_list = []\n",
    "for text in text_list:\n",
    "    if any(x in text for x in see_other):\n",
    "        continue\n",
    "    if any(re.search(x, text) for x in variant_of):\n",
    "        continue\n",
    "    new_list.append(text)\n",
    "\n",
    "text_list = new_list\n",
    "name_info_df = pd.DataFrame()\n",
    "basic_name_lists = []\n",
    "for text in tqdm(text_list):\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    text = re.sub(missed_space, r'\\1 \\2', text)\n",
    "    text = re.sub(missed_space2, r'\\1 \\2', text)\n",
    "    text = re.sub(missed_space3, r'\\1 \\2', text)\n",
    "    if not any(x in text for x in permitted_origins):\n",
    "        continue\n",
    "\n",
    "\n",
    "    name = re.search(start_name_block, text).group(1)\n",
    "\n",
    "    if re.search(variants, text):\n",
    "        variants_text = re.search(variants, text).group(1)\n",
    "        variants_list = variants_text.split(',')\n",
    "        variants_list = [x.strip() for x in variants_list]\n",
    "    else:\n",
    "        variants_list = []\n",
    "    new_name_list = [name] + variants_list\n",
    "    basic_name_lists.append(new_name_list)\n",
    "\n",
    "    origins = re.split(r'\\n\\d ', text)\n",
    "    origins = origins[1:]\n",
    "    occup = 0\n",
    "    occupation = ''\n",
    "    loc = 0\n",
    "    topo = 0\n",
    "    nick = 0\n",
    "    rel = 0\n",
    "    location = ''\n",
    "    location_in = ''\n",
    "    county = ''\n",
    "    for section_text in origins:\n",
    "\n",
    "\n",
    "        # Let's grab the \"early bearers\" section\n",
    "        if re.search(early_bearers, section_text):\n",
    "            early_bearers_section = section_text.split('\\nEarly bearers:')[1]\n",
    "            early_bearers_section = re.split(r'\\nReferences:', early_bearers_section)[0]\n",
    "            early_bearers_section = re.sub(r'\\n', ' ', early_bearers_section)\n",
    "            early_bearers_section = re.sub(r'\\s+', ' ', early_bearers_section)\n",
    "            early_bearers_section = early_bearers_section.strip()\n",
    "            doc = nlp(early_bearers_section)\n",
    "            early_bearer_list = []\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == 'PERSON':\n",
    "                    ent_name = ent.text\n",
    "                    ent_name_list = ent_name.split(' ')\n",
    "                    if len(ent_name_list) == 2:\n",
    "                        ent_surname = ent_name_list[1]\n",
    "                    elif len(ent_name_list) == 3:\n",
    "                        if ent_name_list[1].lower() in ['de', 'des', 'le', 'dil', 'del', 'at', 'of', 'atte', 'ate', 'a', '(le)', 'ad', 'la',]:\n",
    "                            ent_surname = ent_name_list[2]\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "                    if ent_surname not in early_bearer_list:\n",
    "                        early_bearer_list.append(ent_surname)\n",
    "        new_name_set = set(new_name_list) | set(early_bearer_list)\n",
    "        new_name_list = list(new_name_set)               \n",
    "        \n",
    "        # Extracting the description of the name\n",
    "        section_text = re.split(r'\\nEarly Bearers:', section_text)[0]\n",
    "        section_text = re.split(r'\\nReferences:', section_text)[0]\n",
    "        if re.search(occupational_surname, section_text):\n",
    "            occup = 1\n",
    "            if re.search(occupational_surname_pattern, section_text):\n",
    "                occupation = re.search(occupational_surname, section_text).group(1)\n",
    "        if re.search(locative_surname, section_text):\n",
    "            loc = 1\n",
    "\n",
    "            if re.search(locative_surname_pattern, section_text):\n",
    "                location = re.search(locative_surname_pattern, section_text).group(1)\n",
    "                if re.search(locative_surname_pattern, section_text).group(2):\n",
    "                    location_in = re.search(locative_surname_pattern, section_text).group(2)\n",
    "                county = re.search(locative_surname_pattern, section_text).group(3)\n",
    "        if re.search(topo_surname, section_text):\n",
    "            topo = 1\n",
    "        if re.search(nickname, section_text):\n",
    "            nick = 1\n",
    "        if re.search(relationship_name, section_text):\n",
    "            rel = 1\n",
    "    for name in new_name_list:\n",
    "        new_row_dict = {'surname': name,\n",
    "                        'occup': occup,\n",
    "                        'occupation': occupation,\n",
    "                        'loc': loc,\n",
    "                        'location': location,\n",
    "                        'location_in': location_in,\n",
    "                        'county': county,\n",
    "                        'topo': topo,\n",
    "                        'nick': nick,\n",
    "                        'rel': rel}\n",
    "        for origin in permitted_origins:\n",
    "            if origin in text:\n",
    "                new_row_dict[origin] = 1\n",
    "            else:\n",
    "                new_row_dict[origin] = 0\n",
    "        new_row = pd.DataFrame(new_row_dict, index=[0])\n",
    "        name_info_df = pd.concat([name_info_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "name_info_df = name_info_df.sort_values(by='surname')\n",
    "name_info_df.to_csv(f'{PROCESSED}/surname_info.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87b955",
   "metadata": {},
   "source": [
    "#### Combining the Name Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fedc5dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "['Agard', 'Eggers', 'Eager', 'Augar', 'Algie', 'Eagger', 'Elgar', 'Ashard', 'Alger', 'Hagger', 'Eagers', 'Allgar', 'Adgar', 'Haggar', 'Hagar', 'Haggard', 'Agar', 'Eagar', 'Hager', 'Auker', 'Agars', 'Augur', 'Elger', 'Egarr', 'Ager', 'Hatchard', 'Egar', 'Hagard', 'Haggart', 'Agger', 'Edgar', 'Egger', 'Eggar', 'Auger', 'Adger', 'Agers', 'Algar', 'Eger', 'Edger', 'Achard']\n",
      "['Aldis', 'Oliff', 'Hollen', 'Hollies', 'Holey', 'Ollive', 'Awdas', 'Holly', 'Aldhouse', 'Holliss', 'Alldis', 'Holley', 'Audus', 'Holles', 'Hollings', 'Aldous', 'Hollis', 'Holling', 'Olive', 'Audiss', 'Ollis', 'Hollan', 'Aldus', 'Hollins', 'Hollens', 'Audas', 'Hollin', 'Olliff', 'Olliffe', 'Aldhous', 'Oldis', 'Aldiss']\n",
      "['Allatt', 'Hayllar', 'Elwood', 'Hellyer', 'Adlard', 'Ellard', 'Hiller', 'Hullah', 'Hallward', 'Hilyard', 'Allett', 'Hilleard', 'Helliar', 'Alwood', 'Ellwood', 'Hayler', 'Eliott', 'Allwood', 'Ellett', 'Hilliar', 'Heller', 'Aylard', 'Hillyer', 'Hilliard', 'Helyar', 'Helyer', 'Eliot', 'Allars', 'Ullah', 'Hellyar', 'Ellers', 'Ilott', 'Allott', 'Aylott', 'Hillyard', 'Huller', 'Elliot', 'Alt', 'Hulyer', 'Eller', 'Hully', 'Allt', 'Hillyar', 'Hallard', 'Haylor', 'Ilett', 'Hilyer', 'Ellyatt', 'Allart', 'Hullyer', 'Aylett', 'Hellard', 'Alliott', 'Haler', 'Allitt', 'Hulley', 'Ellor', 'Hallett', 'Ellerd', 'Adler', 'Allard', 'Hellier', 'Eylott', 'Hildyard', 'Hallet', 'Hillard', 'Hillier', 'Ulley', 'Ellert', 'Elliott']\n",
      "['Allebone', 'Alliband', 'Albones', 'Alabone', 'Alban', 'Albin', 'Hallibone', 'Allbone', 'Allibon', 'Albon', 'Albone', 'Alliban', 'Hallybone', 'Alibone', 'Hollebon', 'Albans', 'Allaban', 'Elborn', 'Hollobone', 'Allbon', 'Elbourne', 'Aubon', 'Allbones', 'Allibone', 'Allebon', 'Elbourn']\n",
      "['Allen', 'Aland', 'Hallum', 'Allom', 'Allyn', 'Halling', 'Allam', 'Holland', 'Oldland', 'Hulland', 'Hallin', 'Alleyn', 'Allum', 'Alleyne', 'Alen', 'Hallums', 'Hallam', 'Allams', 'Allon', 'Allan', 'Hawling', 'Alain', 'Allain', 'Hallen', 'Howland', 'Hollands', 'Hulands', 'Allanach', 'Hoyland', 'Hallan', 'Hullands', 'Alland', 'Allin', 'Alan', 'Alling']\n",
      "['Ardern', 'Harden', 'Hordon', 'Hardey', 'Hardeman', 'Harding', 'Hirdman', 'Hardinge', 'Hardin', 'Ardin', 'Arden', 'Arding', 'Le Hardy', 'Hardee', 'Herdman', 'Hardman', 'Hurden', 'Hardiman', 'Hardiment', 'Heardman', 'Hardy', 'Hardyman', 'Horden', 'Hurdman', 'Hardie']\n",
      "['Attale', 'Hale', 'Elis', 'Hellis', 'Haile', 'Ayles', 'Heel', 'Ally', 'Eales', 'Heal', 'Hell', 'Hills', 'Hallows', 'Hiles', 'Ellis', 'Heels', 'Hillhouse', 'Hill', 'Alle', 'Halls', 'Hille', 'Elliss', 'Ailes', 'Elles', 'Eeles', 'Halle', 'Else', 'Hillis', 'Hall', 'Elys', 'Hayles', 'Ell', 'Allee', 'Alley', 'Heelas', 'Haill', 'Hile', 'Hayle', 'Hele', 'Ale', 'Heales', 'Heelis', 'Hails', 'All', 'Ells', 'Eele', 'Hillas', 'Ellice', 'Hales', 'Hailes', 'Heale', 'Alls']\n",
      "['Bayliss', 'Baile', 'Baylis', 'Baley', 'Baily', 'Baileff', 'Bale', 'Bail', 'Bayless', 'Baylie', 'Baly', 'Bailiss', 'Bails', 'Bailess', 'Baillie', 'Baylay', 'Bales', 'Bayle', 'Bayliffe', 'Bailey', 'Bailes', 'Bailiff', 'Bayles', 'Bayliff', 'Bayly', 'Bayley', 'Bally']\n",
      "['Boulsover', 'Bellshaw', 'Bolsover', 'Bucher', 'Burgher', 'Beushaw', 'Bowcher', 'Butchers', 'Bowser', 'Bircher', 'Boutcher', 'Bourchier', 'Beazer', 'Bezer', 'Bucker', 'Bouchard', 'Bewsher', 'Bourcier', 'Burger', 'Burker', 'Belsher', 'Booker', 'Bewshea', 'Beausire', 'Belcher', 'Bosher', 'Borger', 'Burcher', 'Bowker', 'Busher', 'Bewsey', 'Buchard', 'Butchart', 'Boucher', 'Belshaw', 'Butcher', 'Butchard', 'Bowsher', 'Bouchier']\n",
      "['Brameld', 'Branwell', 'Brammah', 'Brambell', 'Bromell', 'Brumell', 'Bransfield', 'Bramhall', 'Bramhill', 'Bromwell', 'Brumble', 'Brammer', 'Brammall', 'Bramall', 'Bramwell', 'Brimble', 'Bromhall', 'Bramah', 'Brambles', 'Brummell', 'Brammeld', 'Brummel', 'Brimmell', 'Bramald', 'Broomall', 'Bramble', 'Broomhall', 'Branfield', 'Brumhill']\n",
      "['Burkinshaw', 'Briggenshaw', 'Brockenshaw', 'Briginshaw', 'Brigenshaw', 'Buttenshaw', 'Burtenshaw', 'Birkinshaw', 'Brigginshaw', 'Burtonshaw', 'Brokenshire', 'Bertenshaw', 'Buttonshaw', 'Buttanshaw', 'Burkimsher', 'Burkenshaw', 'Brokenshaw', 'Burtinshaw', 'Birkenshaw', 'Bircumshaw', 'Bruckshaw']\n",
      "['Bury', 'Burrus', 'Burrough', 'Burrows', 'Burris', 'Burress', 'Barrows', 'Boroughs', 'Burrow', 'Burrowes', 'Burroughs', 'Berry', 'Burra', 'Borrows', 'Borris', 'Borrow', 'Burriss', 'Burroughes', 'Barrass', 'Barrow', 'Berrow', 'Burros', 'Burrous']\n",
      "['Caulcutt', 'Callcut', 'Collacott', 'Colocott', 'Caldicott', 'Cawcutt', 'Collecott', 'Colkett', 'Coldicott', 'Calcott', 'Caldecott', 'Caulkett', 'Collacot', 'Collicutt', 'Calcutt', 'Corcut', 'Collcutt', 'Collicott', 'Calcut', 'Collcott', 'Colcutt', 'Caldecourt', 'Callicott', 'Caldicot', 'Callcott', 'Corkett', 'Goldicott']\n",
      "['Cawdell', 'Shadwell', 'Cardwell', 'Cauldwell', 'Caudwell', 'Caldwell', 'Cadwell', 'Cadel', 'Coldwell', 'Caudell', 'Chadwell', 'Gulwell', 'Cardall', 'Caddle', 'Cadle', 'Cardle', 'Kadwell', 'Goldwell', 'Caddell', 'Couldwell', 'Cardell', 'Cordwell', 'Shatwell', 'Cardale', 'Caudle', 'Calwell']\n",
      "['Clewett', 'Cluett', 'Lloyde', 'Lyth', 'Flute', 'Flewitt', 'Floweth', 'Flood', 'Lythe', 'Lyde', 'Cloyd', 'Lloyd', 'Floyd', 'Floyed', 'Float', 'Flowith', 'Loyd', 'Flewett', 'Loyde', 'Loydd', 'Lloyds', 'Flawith', 'Floyde', 'Flowitt', 'Flude', 'Lloydd', 'Floate']\n",
      "['Colls', 'Collyns', 'Mc Collin', 'Coole', 'Coales', 'Coules', 'Cullins', 'Cowle', 'Cullon', 'Collis', 'Cowling', 'Cole', 'Coal', 'Coleing', 'Cowl', 'Cullens', 'Cullan', 'Coule', 'Cowell', 'Coles', 'Quillan', 'Coull', 'Cullin', 'Cowls', 'Coale', 'Cullen', 'Collinge', 'Coll', 'Collins', 'Collings', 'Cowel', 'Colling', 'Coul', 'Cowles', 'Colins', 'Coling', 'Collens']\n",
      "['Crosswell', 'Creswell', 'Cressell', 'Grizzle', 'Grissell', 'Caswell', 'Kerswell', 'Cressall', 'Crisswell', 'Caswall', 'Cresswell', 'Crisell', 'Gresswell', 'Caswill', 'Crissell', 'Grizzell', 'Criswell', 'Careswell', 'Craswell', 'Casswell', 'Crasswell', 'Carswell', 'Kerswill', 'Casewell']\n",
      "['Darkin', 'Daykin', 'Haken', 'Dorkins', 'Durkan', 'Darken', 'Dorking', 'Dakins', 'Darkings', 'Dalkin', 'Dakin', 'Dirkin', 'Darking', 'Mc Gurgan', 'Dawkins', 'Durcan', 'Dorkings', 'Durgan', 'Darkins', 'Dawkin', 'Hakin', 'Derkin', 'Durkin', 'Dorkin', 'Dirken']\n",
      "['Daynes', 'Deane', 'Dain', 'Adeane', 'Dane', 'Mc Dine', 'Dine', 'Daine', 'Dyne', 'Danes', 'Deanes', 'Deans', 'Dines', 'Dann', 'Doyne', 'Dean', 'Dayne', 'Dynes', 'Dan', 'Deen', 'Dene', 'Dains', 'Daines']\n",
      "['Deighan', 'Duggins', 'Diggon', 'Digan', 'Tacon', 'Digings', 'Duggon', 'Dogan', 'Deegan', 'Diggines', 'Digance', 'Doogan', 'Takon', 'Dagon', 'Degan', 'Diggins', 'Dagan', 'Diggan', 'Duggan', 'Dougan', 'Duggin', 'Diggens', 'Dugan', 'Diggin']\n",
      "['Demant', 'Dimon', 'Damant', 'Dimond', 'Dayment', 'Diamond', 'Dimont', 'Diment', 'Dyment', 'Damon', 'Dayman', 'Demmon', 'Demaine', 'Deman', 'Daymon', 'Diamant', 'Dymond', 'Demain', 'Dumayne', 'Demand', 'Daymond']\n",
      "['Dewe', 'Gower', 'Goward', 'Dew', 'Dewes', 'Dewse', 'Defoe', 'Jewhurst', 'Goar', 'Jewers', 'Dewhirst', 'Jewiss', 'Devis', 'Gore', 'Durose', 'Devos', 'Devas', 'Dewis', 'Doo', 'Dewhurst', 'Jowers', 'Deuce', 'Due', 'Dews', 'Gowar', 'Gurr', 'Jewess', 'Gowers', 'Devo', 'Gare', 'Devoe']\n",
      "['Dunicliff', 'Tunicliffe', 'Townley', 'Townsley', 'Tunaley', 'Towneley', 'Tunncliffe', 'Tunacliffe', 'Tunnycliff', 'Tomley', 'Dunnicliff', 'Tunnicliff', 'Thomley', 'Tunnacliffe', 'Tunncliff', 'Tunnicliffe', 'Dunicliffe', 'Dunnicliffe', 'Tunicliff', 'Tunnecliff', 'Townly', 'Tunley']\n",
      "['Eastall', 'Eastell', 'Haskel', 'Easthill', 'Esdale', 'Eskdale', 'Easdale', 'Eskell', 'Axton', 'Axell', 'Haskell', 'Axtell', 'Axten', 'Haxell', 'Easteal', 'Estill', 'Easthall', 'Askill', 'Axtens', 'Estall', 'Estell', 'Ashwell', 'Ashkettle', 'Axcell', 'Askell', 'Hackshall']\n",
      "['Eastern', 'Haysom', 'Essam', 'Isom', 'Haysham', 'Hase', 'Heighes', 'Izant', 'Heys', 'Eason', 'Ison', 'Haye', 'Heeson', 'Hye', 'Hazan', 'Heyes', 'Izon', 'Easdon', 'Easdown', 'Hassen', 'Hease', 'Ace', 'Hassan', 'Easton', 'Neston', 'Issom', 'Delahaye', 'Easen', 'Hays', 'Hawson', 'Hayes', 'Eastham', 'Haysum', 'Hay', 'Essen', 'Eston', 'Hyson', 'Easten', 'Highe', 'Easom', 'Esten', 'Easun', 'Easting', 'Halson', 'High', 'Hayson', 'Aze', 'Hey', 'Heesom', 'Hason', 'Hie', 'Hasson', 'Ayson', 'Esson', 'Heysham', 'Isham']\n",
      "['Emmons', 'Edmunds', 'Edman', 'Haddenham', 'Immins', 'Adnam', 'Emmans', 'Emmins', 'Hemings', 'Edmons', 'Emmony', 'Hadman', 'Emmonds', 'Edmund', 'Edmands', 'Emeney', 'Edmans', 'Hadingham', 'Emney', 'Hemmins', 'Emmence', 'Edmond', 'Adnams', 'Emens', 'Emans', 'Emond', 'Hemmings', 'Emmings', 'Eman', 'Edmonds', 'Emons', 'Hemmens', 'Emin', 'Adman', 'Emeny', 'Hemans', 'Emmens', 'Hadenham']\n",
      "['Farrey', 'Ferrer', 'Pharro', 'Ferro', 'Ferrar', 'Faro', 'Farah', 'Fara', 'Farrer', 'Farrow', 'Farrar', 'Pharaoh', 'Pharoah', 'Varey', 'Farrah', 'Ferrow', 'Pharo', 'Farra', 'Vero', 'Farry', 'Farrier', 'Ferrier', 'Varo']\n",
      "['Ferron', 'Feron', 'Ferrey', 'Ferri', 'Ferrin', 'Ferran', 'Ferrans', 'Ferens', 'Farrants', 'Ferry', 'Farrand', 'Fearon', 'Farrans', 'Ferrant', 'Farrant', 'Ferren', 'Verran', 'Farren', 'Farran', 'Farrands', 'Ferrand', 'Farrance', 'Fearing', 'Ferrie']\n",
      "['Ficke', 'Figge', 'Figg', 'Faulks', 'Fetch', 'Feck', 'Veck', 'Feakes', 'Feaks', 'Faux', 'Falkous', 'Fidge', 'Figgis', 'Faulkes', 'Falk', 'Fawkes', 'Fitz', 'Fakes', 'Fice', 'Fytche', 'Falcus', 'Figures', 'Falck', 'Fitch', 'Figgess', 'Fitze', 'Fake', 'Feek', 'Fawke', 'Vick', 'Feak', 'Fawcus', 'Fitches', 'Falkus', 'Fick']\n",
      "['Fook', 'Flook', 'Voke', 'Fuche', 'Fudge', 'Fuidge', 'Fuke', 'Fuge', 'Volke', 'Focke', 'Flooks', 'Fogg', 'Fulk', 'Foulke', 'Fluke', 'Flux', 'Fog', 'Folk', 'Fowke', 'Voak', 'Folke', 'Fluck', 'Foulk', 'Flock', 'Volk']\n",
      "['Furney', 'Fernell', 'Furness', 'Vernals', 'Vennall', 'Furnell', 'Farnill', 'Funnell', 'Vennell', 'Farnish', 'Farnall', 'Fendel', 'Fennel', 'Vernall', 'Findull', 'Vernalls', 'Furnish', 'Furniss', 'Findall', 'Vinell', 'Fendle', 'Vinnell', 'Farndell', 'Vernal', 'Fennell', 'Varndell', 'Findell', 'Farnell', 'Varnell', 'Varnals', 'Funnelle', 'Varnish', 'Fearnall', 'Farnel', 'Farnhill', 'Furneaux', 'Varndall', 'Fendall', 'Fennelly', 'Fendell', 'Final', 'Furnace']\n",
      "['Gerrad', 'Jarrold', 'Jarret', 'Jerred', 'Kellard', 'Gerard', 'Gerrett', 'Giller', 'Geal', 'Gyle', 'Jarrott', 'Gaule', 'Galt', 'Gaw', 'Gerrard', 'Gerratt', 'Jarritt', 'Guile', 'Garrott', 'Gillatt', 'Jellis', 'Jared', 'Garrould', 'Jell', 'Gerold', 'Geller', 'Jiles', 'Gil', 'Garrod', 'Jarred', 'Garred', 'Gill', 'Garretts', 'Jerrold', 'Gell', 'Jarrard', 'Jarrett', 'Garrad', 'Geall', 'Gillard', 'Gerred', 'Gaul', 'Garard', 'Gyles', 'Garratt', 'Garret', 'Gelle', 'Jerrard', 'Gills', 'Jeal', 'Gilyard', 'Jarrod', 'Girard', 'Garrard', 'Garritt', 'Gilleard', 'Gillett', 'Jillard', 'Gile', 'Jerwood', 'Gerald', 'Guiler', 'Gilliard', 'Geralds', 'Jerrett', 'Jarrad', 'Gall', 'Garrett', 'Garrat', 'Jellard', 'Garwood', 'Geale', 'Jarratt', 'Gorrod', 'Guyler', 'Garrood', 'Jerratt', 'Jelliss', 'Giles']\n",
      "['Greenhill', 'Grinnall', 'Cornah', 'Grunnell', 'Carnwell', 'Gornell', 'Cronie', 'Gornall', 'Corness', 'Cornell', 'Groundwell', 'Greenwell', 'Cornwell', 'Greenhouse', 'Cardinal', 'Greenhall', 'Greenhalf', 'Gurnell', 'Carnall', 'Garnell', 'Cornhill', 'Greeno', 'Grindal', 'Corn', 'Grunwell', 'Grindell', 'Croney', 'Grindel', 'Gronow', 'Corney', 'Greenall', 'Crowner', 'Crowney', 'Carnell', 'Grunnill', 'Cornes', 'Cornwall', 'Greenalgh', 'Cornish', 'Grindale', 'Croner', 'Goronwy', 'Corne', 'Corner', 'Grinnell', 'Gurnhill', 'Coroner', 'Grindle', 'Greenhough', 'Grennell', 'Greenhalgh', 'Cornall', 'Grindall', 'Grenow', 'Cardnell']\n",
      "['Haseldene', 'Hazleton', 'Heseltine', 'Haselton', 'Haizelden', 'Aseltine', 'Hesselden', 'Hayzelden', 'Hayselden', 'Haseldine', 'Hasleden', 'Heselden', 'Hazeldon', 'Haselden', 'Hazledine', 'Hazeldene', 'Hazelden', 'Heselton', 'Hazzledine', 'Hazeldine', 'Heseldin', 'Haseltine', 'Hazelton', 'Haiselden', 'Hesleden', 'Hesseltine', 'Haszeldine', 'Hazeltine']\n",
      "['Haugh', 'Huws', 'Haws', 'Husey', 'Hoose', 'Hewes', 'Huyshe', 'Houfe', 'Hughff', 'Hews', 'Howis', 'Hoo', 'Hose', 'Hooff', 'Howe', 'Hawyes', 'Hauff', 'Hows', 'Hawse', 'Hoes', 'Howse', 'Hussey', 'Hoff', 'Hewis', 'Hughs', 'Hussy', 'Hoe', 'Huff', 'Heugh', 'Huzzey', 'House', 'How', 'Haw', 'Hughes', 'Hoof', 'Huse', 'Hughf', 'Hewish', 'Howes', 'Hough', 'Hawes', 'Huish', 'Hosey']\n",
      "['Hembury', 'Damery', 'Embry', 'Emery', 'Hembry', 'Emberry', 'Embery', 'Dimery', 'Imrie', 'Demery', 'Hemery', 'Amory', 'Damry', 'Dammery', 'Emburey', 'Imbery', 'Ambery', 'Ambers', 'Damary', 'Imray', 'Emerick', 'Amori', \"D'Amery\", 'Hembra', 'Embury', 'Imbrey', 'Emory', 'Imery', 'Emary', 'Hembery', 'Amery', 'Hembrough', 'Amber', 'Embra', 'Embrey', 'Hembrey']\n",
      "['Henchcliffe', 'Ion', 'Henchcliff', 'Haine', 'Inch', 'Haines', 'Hinchcliffe', 'Hint', 'Hinchley', 'Hayns', 'Ennis', 'Hinchcliff', 'Inchley', 'Eno', 'Insley', 'Hynd', 'Ines', 'Hines', 'Enos', 'Hagin', 'Hagans', 'Hinds', 'Hincliff', 'Innes', 'Hane', 'Innis', 'Hinchsliff', 'Hanes', 'Hinchey', 'Hain', 'Hincliffe', 'Hennah', 'Hindes', 'Hinch', 'Hinchliff', 'Hagon', 'Ilsley', 'Hinsley', 'Inns', 'Ions', 'Hynds', 'Hinchliffe', 'Fagan', 'Hince', 'Ince', 'Hagen', 'Henna', 'Hacken', 'Heyne', 'Hinchly', 'Hyne', 'Hind', 'Aynes', 'Hains', 'Hacon', 'Hagan', 'Hine', 'Hinchsliffe', 'Hayne', 'Hindsley', 'Heynes', 'Hacking', 'Hackin', 'Hinde', 'Illsley', 'Haynes', 'Hynes', 'Hein', 'Hints', 'Haggan']\n",
      "['Herold', 'Harral', 'Harrild', 'Herald', 'Harrad', 'Harrell', 'Harold', 'Harrall', 'Yarrell', 'Herod', 'Herrell', 'Herrald', 'Herrod', 'Harrod', 'Harrald', 'Herrold', 'Harrold', 'Harald', 'Horrod', 'Herrall', 'Harrel']\n",
      "['Hewell', 'Hole', 'Ewell', 'Yeowell', 'Yowell', 'Holl', 'Youle', 'Yull', 'Houle', 'Youhill', 'Youles', 'Youll', 'Hoiles', 'Hoyles', 'Hoile', 'Yoell', 'Yeuell', 'Euell', 'Hoyle', 'Youell', 'Youel', 'Holes']\n",
      "['Hibbard', 'Herberts', 'Harbard', 'Harberd', 'Hibberd', 'Harbut', 'Hebbard', 'Harbert', 'Herbert', 'Hebard', 'Hilbert', 'Harbutt', 'Harbot', 'Harbud', 'Hibbert', 'Harbott', 'Harbird', 'Harbord', 'Ilbert', 'Hebberd', 'Hebbert']\n",
      "['Hillen', 'Hilland', 'Heyland', 'Ayling', 'Hayland', 'Highlands', 'Hyland', 'Alin', 'Hailing', 'Aylin', 'Aling', 'Hillan', 'Hylan', 'Ayland', 'Hilliam', 'Highland', 'Hillum', 'Hylands', 'Hayling', 'Hillam', 'Aylen']\n",
      "['Hodgins', 'Hodgskin', 'Hotchkin', 'Hodgshon', 'Hodgskins', 'Hodsdon', 'Hodgson', 'Hodgon', 'Hutson', 'Hudson', 'Hodgeon', 'Hodgkiess', 'Hodges', 'Hadgkiss', 'Hochkins', 'Hodson', 'Hodgkins', 'Hodgeson', 'Hotchkis', 'Hodge', 'Hodgens', 'Hodkin', 'Hotson', 'Hotston', 'Hodgkin', 'Hodgkiss', 'Hogson', 'Hoggins', 'Hodgin', 'Hotchkiss', 'Hodgen']\n",
      "['Lambe', 'Lown', 'Lound', 'Lond', 'Lount', 'Lunnon', 'London', 'Loombe', 'Lonnon', 'Lund', 'Lownes', 'Loomes', 'Loom', 'Lamp', 'Lomb', 'Lumm', 'Lamb', 'Lounds', 'Lownds', 'Lamm', 'Lunt', 'Loundes', 'Lowndes', 'Lundon', 'Looms', 'Lumb', 'Lowne', 'Lum', 'Lonnen', 'Lunn']\n",
      "['Leaney', 'Dulaney', 'Delauney', 'Leen', 'Laine', 'Delany', 'Lain', 'Layne', 'Lyon', 'Lyne', 'Lone', 'Lines', 'De\\nLauney', 'Lane', 'Laynes', 'Lyons', 'Lynas', 'Laney', 'Line', 'Lyness', 'Landy', 'De Launay', 'Laundy', 'Layen', 'Lion', 'Lynes', 'Loan', 'Lanes', 'Lones', 'Delaney']\n",
      "['Lear', 'Eayres', 'Ayriss', 'Ayr', 'Hare', 'Leir', 'Hayers', 'Layer', 'Hoyer', 'Aiers', 'Ayers', 'Aers', 'Ayres', 'Ayer', 'Hayer', 'Eyres', 'Airs', 'Eyers', 'Leer', 'Eyer', 'Eayrs', 'Aires', 'Haire', 'Ayre', 'Hair', 'Hayre', 'Eyre', 'Heyer', 'Ayris']\n",
      "['Living', 'Lewing', 'Livings', 'Lowings', 'Levens', 'Livens', 'Lovin', 'Leven', 'Levin', 'Lewins', 'Liffen', 'Lowin', 'Lewens', 'Loving', 'Lowen', 'Lewin', 'Levings', 'Lowing', 'Leavens', 'Levins', 'Liveing', 'Levinge']\n",
      "['Lukas', 'Lucus', 'Lukehurst', 'Levick', 'Luke', 'Leffek', 'Loukes', 'Livick', 'Loake', 'Lock', 'Luk', 'Lovick', 'Lukes', 'Luckhurst', 'Lowick', 'Locks', 'Luck', 'Mc Lucas', 'Locke', 'Look', 'Livock', 'Lucas']\n",
      "['Mail', 'Mell', 'Madel', 'Madle', 'Madewell', 'Males', 'Mailes', 'Meale', 'Maydwell', 'Mally', 'Mailey', 'Malley', 'Madell', 'Mayle', 'Maile', 'Male', 'Meadwell', 'Maydell', 'Meal', 'Mayles', 'Maidwell', 'Mayall', 'Medwell', 'Meals']\n",
      "['Manterfield', 'Manfield', 'Manwell', 'Mandal', 'Mandale', 'Manifield', 'Manville', 'Manvill', 'Mandel', 'Munfield', 'Mountfield', 'Manderfield', 'Mannifield', 'Masefield', 'Manvell', 'Mandeville', 'Mandfield', 'Manwill', 'Mandefield', 'Mansfield', 'Mounfield', 'Meanwell', 'Mandell', 'Manderville', 'Mundell']\n",
      "['Mc Entyre', 'Tice', 'Tease', 'Taye', 'Teoh', 'Tye', 'Theyer', 'Tees', 'Thayre', 'Tyres', 'Tyre', 'Thair', 'Tey', 'Mc Teer', 'Tea', 'Mc Tier', 'Mc Tyre', 'Mc Intire', 'Teo', 'Mc Intyre', 'Tyers', 'Thier', 'Mc Entire', 'Thyer', 'Teece', 'Tai', 'Mc Teir', 'Teese', 'Thaire', 'Thiers', 'Mc Inteer', 'Tee', 'Tyas', 'Tier', 'Tyass', 'Thayer', 'Tay']\n",
      "['Morrice', 'Mori', 'Moor', 'Morice', 'Morrish', 'Morehouse', 'Morey', 'More', 'Morse', 'Morris', 'Mawer', 'Morrey', 'Mower', 'Mory', 'Morry', 'Mores', 'Moris', \"O'Moore\", 'Morriss', 'Morres', 'Morss', 'Morries', 'Moors', 'Moorse', 'Moorhouse', 'Maurice', 'Moore', 'Morie', 'Moorehouse', 'Maury', 'Moores', 'Murr']\n",
      "['Moulds', 'Mille', 'Mahood', 'Mallott', 'Miles', 'Mallette', 'Mighell', 'Myall', 'Mallord', 'Mallett', 'Mallock', 'Mawhood', 'Moyles', 'Mules', 'Miell', 'Molde', 'Mault', 'Mihill', 'Molt', 'Moule', 'Moult', 'Moll', 'Myhill', 'Mullis', 'Mould', 'Mowat', 'Mold', 'Mallet', 'Maude', 'Malet', 'Moles', 'Moyle', 'Mallard', 'Mihell', 'Mulliss', 'Miall', 'Myles', 'Mills', 'Mole', 'Malt', 'Mallot', 'Maud', 'Mowle', 'Mill', 'Mighall', 'Mule']\n",
      "['Neals', 'Neele', 'Neels', 'Neill', 'Neil', 'Nihell', 'Niall', 'Knell', 'Neild', 'Neel', 'Neale', 'Nell', 'Neall', 'Niel', 'Nel', 'Neal', 'Niell', 'Nield', 'Nihill', 'Neeld', 'Neils', 'Nile']\n",
      "['Peeks', 'Petch', 'Spake', 'Speck', 'Peachy', 'Speak', 'Peach', 'Pechey', 'Speke', 'Peeke', 'Peck', 'Spack', 'Spetch', 'Speake', 'Peachey', 'Peech', 'Petchey', 'Peak', 'Peaks', 'Petche', 'Speakes', 'Speaks', 'Speeks', 'Peek', 'Peake', 'Peache']\n",
      "['Pheazey', 'Phasey', 'Voysey', 'Pheasey', 'Veasy', 'Vezey', 'Voisey', 'Foizey', 'Feesey', 'Phazey', 'Vasey', 'Feasey', 'Feazey', 'Veasey', 'Facey', 'Phaisey', 'Veysey', 'Veazey', 'Feacey', 'Voyzey', 'Vaizey', 'Pheysey', 'Vaisey', 'Voizey', 'Fasey', 'Faizey', 'Vesey', 'Fazey', 'Fessey']\n",
      "['Powling', 'Pauly', 'Palin', 'Pulling', 'Pawling', 'Pollin', 'Polland', 'Pauline', 'Polling', 'Pullen', 'Pauling', 'Pollen', 'Pulham', 'Pavelin', 'Pailing', 'Pulleyn', 'Paulley', 'Palling', 'Payling', 'Pauley', 'Poland', 'Pally', 'Paley', 'Paulin', 'Pullein', 'Pawlyn', 'Pullin', 'Paulling', 'Pullins', 'Pavely', 'Paling', 'Paveley', 'Pullum', 'Pullan', 'Pallant', 'Pullam', 'Polan', 'Polin', 'Pollins', 'Pulleine', 'Pawley', 'Powley', 'Pullon']\n",
      "['Ralle', 'Ralph', 'Rawll', 'Reay', 'Rout', 'Row', 'Rawe', 'Rove', 'Rolt', 'Roaf', 'Rayworth', 'Rawle', 'Rawes', 'Rey', 'Wroe', 'Rall', 'Rulf', 'Rea', 'Rowett', 'Reyes', 'Rowed', 'Wray', 'Raw', 'Wrey', 'Raff', 'Rooth', 'Rawles', 'Rawl', 'Roult', 'Rafe', 'Raye', 'Raywood', 'Roof', 'Roworth', 'Rhea', 'Ralfs', 'Roffe', 'Roalfe', 'Roo', 'Rowe', 'Ralls', 'Raworth', 'Ralf', 'Ray', 'Roofe', 'Rouf', 'Rolph', 'Rolf', 'Rawls', 'Ree', 'Ralfe', 'Rayes', 'Rho', 'Rofe', 'Rolfe', 'Rohard', 'Roff', 'Rae', 'Rye', 'Ralphs', 'Routh', 'Roe', 'Roward', 'Rau', 'Ruff', 'Rauf', 'Roll', 'Rowarth']\n",
      "['Rayford', 'Reavell', 'Revels', 'Raffield', 'Ravell', 'Revell', 'Raffell', 'Raphael', 'Raffel', 'Raffle', 'Ravald', 'Revill', 'Revel', 'Reville', 'Rivell', 'Ravel', 'Revelle', 'Rayfield', 'Raffles', 'Reavill', 'Reevell']\n",
      "['Roleston', 'Rolstone', 'Rollisson', 'Rowlinson', 'Roulstone', 'Rallison', 'Rolinson', 'Rollingson', 'Rouson', 'Rolison', 'Rolston', 'Rawlingson', 'Rollston', 'Rowlandson', 'Rawlison', 'Rowson', 'Rollason', 'Rollison', 'Roulston', 'Ronson', 'Rowlerson', 'Rowlstone', 'Rolleston', 'Rawlinson', 'Rowlingson', 'Rawson', 'Rollerson', 'Roulson', 'Rollinson']\n",
      "['Seal', 'Shail', 'Sayles', 'Saul', 'Shayle', 'Sallows', 'Shall', 'Sales', 'Shale', 'Sallis', 'Seels', 'Saile', 'Seel', 'Zeal', 'Sale', 'Shailes', 'Sayle', 'Seales', 'Shawl', 'Sailes', 'Salles', 'Sails', 'Seals', 'Seale', 'Salliss', 'Selles', 'Shales', 'Zeale', 'Sall', 'Sail', 'Sellis']\n",
      "['Sealey', 'Shelvey', 'Selly', 'Silly', 'Ceeley', 'Selley', 'Ceely', 'Cely', 'Zealey', 'Sheley', 'Sheely', 'Silley', 'Shallow', 'Ceiley', 'Seely', 'Shealy', 'Seelly', 'Shelly', 'Sealy', 'Zealley', 'Shelley', 'Seley', 'Seally', 'Sheeley', 'Seeley', 'Zelley']\n",
      "['Seggar', 'Sedger', 'Shawyer', 'Seagars', 'Saggers', 'Segger', 'Sawyer', 'Siger', 'Seagers', 'Seagar', 'Siggers', 'Segar', 'Sayer', 'Seago', 'Sagger', 'Sawyers', 'Sigger', 'Sawer', 'Seager', 'Saiger', 'Sagar', 'Sager', 'Seger', 'Seeger', 'Sago', 'Seegar']\n",
      "['Simmens', 'Symonds', 'Symmons', 'Seyman', 'Seammen', 'Seamans', 'Southman', 'Simmen', 'Simmins', 'Simon', 'Summon', 'Simmon', 'Simons', 'Symons', 'Sowman', 'Simmons', 'Symon', 'Simones', 'Simmance', 'Semon', 'Seamons', 'Simonds', 'Semens', 'Semmons', 'Seman', 'Seeman', 'Simmans', 'Suman', 'Symond', 'Semmens', 'Seamon', 'Semmence', 'Summan', 'Simond', 'Simmond', 'Summons', 'Simmonds', 'Simans', 'Seaman']\n",
      "['Soon', 'Sanne', 'Hing', 'Suen', 'Sham', 'Sones', 'Samms', 'Ying', 'Shinn', 'Indge', 'Sin', 'Sames', 'Sum', 'Shin', 'Son', 'San', 'Soons', 'Sign', 'Shum', 'Sun', 'Samme', 'Samm', 'Sam', 'Soan', 'Shine', 'Hang', 'Soanes', 'Sine', 'Sams', 'Soans', 'Sans', 'Inge', 'Sen', 'Ing', 'Soane', 'Shen', 'Hinge', 'Sines', 'Sammes', 'Ings', 'Shing', 'Heng', 'Sonn', 'Sing', 'Seah', 'Sone']\n",
      "['Steffens', 'Stines', 'Steen', 'Steene', 'Stephens', 'Stevans', 'Stevens', 'Stayne', 'Stain', 'Stiven', 'Staynes', 'Steane', 'Steyne', 'Stean', 'Staine', 'Stine', 'Steens', 'Stivens', 'Stanes', 'Stephans', 'Steans', 'Stephan', 'Staines', 'Stains', 'Steyn', 'Stein', 'Stephen', 'Steven']\n",
      "['Tibble', 'Tudball', 'Davill', 'Joels', 'Deeble', 'Jewell', 'Dyball', 'Deville', 'Joel', 'Dybell', 'Dible', 'Tidball', 'Theobald', 'Dabell', 'Tebble', 'Debell', 'Tidboald', 'Davall', 'Dewell', 'Davolls', 'Dyble', 'Deavall', 'Jowle', 'Joule', 'Joell', 'De Vile', 'Jewel', 'Evill', 'Duell', 'Devall', 'Dewfall', 'Jowell', 'Theobalds', 'Tibbals', 'Deaville', 'Diboll', 'De Ville', 'Jewels', 'Jules', 'Diable', 'Tibbalds', 'Tibballs', 'Theobold', 'Dipple', 'Divall', 'Dibble', 'Joules', 'Tibbles']\n",
      "['Tomline', 'Tambling', 'Thomlins', 'Turpin', 'Tomlins', 'Tomling', 'Tuplin', 'Tumblin', 'Tamblin', 'Tomalin', 'Tapling', 'Tamlyn', 'Tomlin', 'Tomblin', 'Tamblyn', 'Thomline', 'Tamlin', 'Tombling', 'Toplin', 'Tamplin', 'Tupling', 'Taplin']\n",
      "['Trude', 'Roodhouse', 'Royds', 'Rhodes', 'Roud', 'Rhoads', 'Rodhouse', 'Rhoad', 'Rode', 'Rhoades', 'Rodda', 'Trodd', 'Roydhouse', 'Rhode', 'Roads', 'Roades', 'Rood', 'Rodd', 'Rodes', 'Roddis', 'Road']\n",
      "['Wayte', 'Whaites', 'Waits', 'Wait', 'Wheat', 'Weet', 'Whaite', 'Weate', 'Whait', 'Waite', 'Wheate', 'Weight', 'Wates', 'Weait', 'Whate', 'Wayt', 'Whaits', 'Waitt', 'Waight', 'Wate', 'Waites']\n",
      "['Wharin', 'Garniss', 'Warin', 'Garron', 'Warrant', 'Waring', 'Werren', 'Warn', 'Warrand', 'Warren', 'Garon', 'Garneys', 'Garns', 'Warne', 'Garness', 'Warrens', 'Worne', 'Warran', 'Garnish', 'Warnes', 'Garnes', 'Garn', 'Worn', 'Wearn', 'Garne', 'Wearne']\n",
      "['Wheal', 'Wheale', 'Weale', 'Veall', 'Whall', 'Wheele', 'Walls', 'Valle', 'Weall', 'Weel', 'Vile', 'Wale', 'Walle', 'Veale', 'Whales', 'Veel', 'Weal', 'Wheels', 'Wall', 'Vale', 'Veal', 'Whale', 'Wheals', 'Wheel']\n",
      "['Wolforth', 'Woolatt', 'Ulyate', 'Woolford', 'Woolfoot', 'Ullett', 'Ullyett', 'Woolvett', 'Ulyatt', 'Wollard', 'Ollett', 'Ulliott', 'Ulyett', 'Ullyott', 'Olyett', 'Woollet', 'Woolward', 'Woolard', 'Ullyatt', 'Woollatt', 'Wolford', 'Woollard', 'Woollett', 'Wollett']\n",
      "['Worledge', 'Awdry', 'Woolwright', 'Darter', 'Alldrit', 'Ulrich', 'Wolledge', 'Aldrich', 'Alldrick', 'Woolridge', 'Aldridge', 'Audry', 'Waldridge', 'Allred', 'Hatry', 'Oldridge', 'Aldritt', 'Daltrey', 'Woledge', 'Dawtry', 'Aldrick', 'Daughtrey', 'Alldread', 'Worlledge', 'Aldrige', 'Eldredge', 'Alldrett', 'Alldridge', 'Allwright', 'Daultrey', 'Woolwich', 'Daughtery', 'Aldread', 'Woolidge', 'Dafters', 'Daughters', 'Daughtry', 'Eldridge', 'Eldrett', 'Eldrid', 'Elldred', 'Dealtry', 'Woolrich', 'Daltry', 'Alltree', 'Wooldridge', 'Woolich', 'Alridge', 'Hawtrey', 'Alfreds', 'Woolrych', 'Aldred', 'Wolveridge', 'Dawtrey', 'Alldritt', 'Allderidge', 'Alldred', 'Arlidge', 'Woldridge', 'Ullrich', 'Woodage', 'Alfred', 'Daldry', 'Haytree', 'Woodwright', 'Wolrich', 'Woodridge', 'Allright', 'Alred', 'Aldredge', 'Altree', 'Autry', 'Eldred', 'Audrey', 'Allured', 'Dafter', 'Holdridge', 'Elridge', 'Worlidge', 'Audritt', 'Attree', 'Woolveridge']\n",
      "Max Name Length: 17, Name: Featherstonehaugh\n",
      "Max list Length: 1\n"
     ]
    }
   ],
   "source": [
    "basic_name_sets = [set(x) for x in basic_name_lists]\n",
    "non_combined_name_lists = [x.copy() for x in basic_name_lists]\n",
    "# Combine all sets with any elements in common\n",
    "fixedPoint = False\n",
    "iteration = 0\n",
    "while not fixedPoint:\n",
    "    fixedPoint = True\n",
    "    print('Iteration: ' + str(iteration))\n",
    "    iteration += 1\n",
    "    for i, name_set in enumerate(basic_name_sets):\n",
    "        for name_set2 in basic_name_sets[i+1:]:\n",
    "            if name_set & name_set2:\n",
    "                basic_name_sets.remove(name_set)\n",
    "                basic_name_sets.remove(name_set2)\n",
    "                basic_name_sets.append(name_set | name_set2)\n",
    "                fixedPoint = False\n",
    "                break\n",
    "\n",
    "combined_name_lists = [list(x) for x in basic_name_sets]\n",
    "combined_name_lists.sort()\n",
    "non_combined_name_lists.sort()\n",
    "#%%\n",
    "max = 0\n",
    "for name_list in combined_name_lists:\n",
    "    list_length = len(name_list)\n",
    "    for name in name_list:\n",
    "        if len(name) > max:\n",
    "            max = len(name)\n",
    "            longest = name\n",
    "    if len(name_list) > 20:\n",
    "        print(name_list)\n",
    "print(f'Max Name Length: {max}, Name: {longest}')\n",
    "print(f'Max list Length: {list_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1682cfe9",
   "metadata": {},
   "source": [
    "#### Adding in the surnames from the subsidy indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f736fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c305dba117a74b09917c69bb6c1668a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surname_index_df = pd.read_csv(f'{PROCESSED}/surname_index.csv')\n",
    "index_surnames = surname_index_df['names'].tolist()\n",
    "index_surnames = [ast.literal_eval(x) for x in index_surnames]\n",
    "found = False\n",
    "for index_surname_list in tqdm(index_surnames):\n",
    "    for index_surname in index_surname_list:\n",
    "        for name_list in combined_name_lists:\n",
    "            if index_surname in name_list:\n",
    "                name_list.extend(index_surname_list)\n",
    "                name_list = list(set(name_list))\n",
    "                found = True\n",
    "    if not found:\n",
    "        print('Not Found')\n",
    "        print(index_surname_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5126039",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdadd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PROCESSED}/combined_surnames.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_name_lists, f, indent=4)\n",
    "\n",
    "with open(f'{PROCESSED}/non_combined_surnames.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(non_combined_name_lists, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
